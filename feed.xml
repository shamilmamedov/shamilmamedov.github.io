<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.4">Jekyll</generator><link href="https://shamilmamedov.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://shamilmamedov.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2024-12-20T12:00:46+00:00</updated><id>https://shamilmamedov.github.io/feed.xml</id><title type="html">blank</title><subtitle>Shamil&apos;s professional blog </subtitle><entry><title type="html">Second-order optimization methods</title><link href="https://shamilmamedov.github.io/blog/2023/hessian/" rel="alternate" type="text/html" title="Second-order optimization methods"/><published>2023-09-26T09:00:00+00:00</published><updated>2023-09-26T09:00:00+00:00</updated><id>https://shamilmamedov.github.io/blog/2023/hessian</id><content type="html" xml:base="https://shamilmamedov.github.io/blog/2023/hessian/"><![CDATA[<p style="align: left; text-align:center;"> <img src="/assets/img/blog/first_vs_second_order_own.png" alt="" width="50%"/> <div class="caption">Figure 1. The difference between the first-order and the second-order methods </div> </p> <p>Second-order methods play a crucial role in numerical optimization. Recently, new optimization algorithms, such as <a href="https://github.com/Liuhong99/Sophia">Sophia</a>, have emerged in the field of machine learning that make use of the Hessian (the second-order information) or its approximations to achieve better local minima and faster convergence. In this article, our focus will be on unconstrained optimization, where we’ll explore how the Hessian can be a valuable tool.</p> <h1 id="theoretical-basics">Theoretical basics</h1> <p>Consider a generic optimization problem</p> \[\underset{\theta}{\text{min}} \ \mathcal{L}(\theta, y, \hat y)\] <p>where \(\theta\) represents the decision variables (which are typically the parameters of a neural network) that we aim to optimize, \(y\) corresponds to the true labels, and \(\hat y\) stands for the predictions made by the model with parameters \(\theta\). As an example, consider a practical scenario where we are solving a regression problem to predict house prices, and we are using the Mean Squared Error (MSE) as our loss function.</p> <p>An essential principle in numerical optimization is the <strong>First Order Necessary Condition</strong> (FONC) which states that if \(\theta^\star\) is local minimizer of \(\mathcal L\), then</p> \[\nabla \mathcal L(\theta^\star, \cdot)= 0.\] <p>In simple terms, when we’ve found a solution, our gradient should be zero. If \(\theta\) is scalar, this condition implies that the derivative of the function at the solution should be zero. The point that satisfies \(\nabla_\theta \mathcal L(\cdot)= 0\) is referred to as a <strong>stationary point</strong> of \(\mathcal L\). Such a point can be either a local minimum, a local maximum, or a saddle point, as depicted in Figure 2.</p> <p style="text-align: center;"> <img src="/assets/img/blog/stationary-points.png" alt="" width="70%"/> <div class="caption">Figure 2. Types of stationary points (<a href="https://mlstory.org/optimization.html" target="_blank">source</a>)</div> </p> <p>Since we are specifically interested in finding local minima, we require another condition that ensures our solution \(\theta^\star\) is not a maxima. This condition is known as the <strong>Second Order Necessary Condition</strong> (SONC), and it states that if \(\theta^\star\) is local minimizer of \(\mathcal L\), then</p> \[\nabla^2_\theta \mathcal L(\theta^\star,\cdot) \succeq 0.\] <p>Here, \(\nabla^2_\theta \mathcal L(\theta^\star,\cdot)\) represents the second derivative of \(\mathcal{L}\) with respect to \(\theta\) and is referred to as the Hessian. Unfortunately, it’s important to note that saddle points also satisfy the SONC, as illustrated in Figure 1. To guarantee that our solution is indeed a local minimum, we need an even stronger condition known as the <strong>Second Order Sufficient Condition</strong> (SOSC): \(\nabla^2_\theta \mathcal L(\theta^\star,\cdot) \succ 0\). Now that we have covered the fundamental theory, let’s explore algorithms that leverage second-order information for optimizing our parameters \(\theta\).</p> <h1 id="exact-newtons-method">Exact Newton’s method</h1> <p>Newton’s method (Newton-Raphson method) is a technique primarily used for solving root-finding problems. In fact, the <strong>First Order Necessary Condition</strong> can be framed as a root-finding problem: we need to find parameters \(\theta^\star\) that make the gradient of the loss function equal to zero. To achieve this, we can apply Newton’s method, which leverages the Taylor series expansion of \(\nabla \mathcal{L}\):</p> \[\begin{align*} \nabla \mathcal L(\theta_k) + \frac{\partial }{\partial \theta} (\nabla \mathcal L(\theta_k))(\theta - \theta_k) = 0, \\ \theta_{k+1} = \theta_k - \nabla^2 \mathcal L(\theta_k)^{-1} \nabla \mathcal L(\theta_k). \end{align*}\] <p>When starting from the loss function \(\mathcal{L}\), we expand it into a Taylor series, considering terms up to the second order. In simpler terms, <strong>Newton’s method locally approximates the loss with a quadratic function, computes the minimum of this quadratic approximation, and iteratively refines it until convergence</strong>, as illustrated in the gif below.</p> <p style="align: left; text-align:center;"> <img src="/assets/img/blog/newton.gif" alt="" width="75%"/> <div class="caption">Visualization of the Newton’s method for finding the minima of a scalar function (<a href="https://jermwatt.github.io/machine_learning_refined/notes/4_Second_order_methods/4_4_Newtons.html" target="_blank">source</a>) </div> </p> <h1 id="newton-type-methods">Newton Type Methods</h1> <p>We saw that Newton’s method relies on the Hessian for parameter updates. However, computing the Hessian can be computationally demanding. As a result, researchers have devised various methods to approximate the Hessian and avoid its explicit computation. Generally, these methods follow a common structure:</p> \[\theta_{k+1} = \theta_k - B_k^{-1}\nabla \mathcal L(\theta_k)\] <h2 id="levenberg-marquardt">Levenberg-Marquardt</h2> <p>Levenberg-Marquardt (LM) is a widely-used method for solving nonlinear least-squares problems, frequently applied in Simultaneous Localization and Mapping (SLAM) for both camera and LiDAR-based. The core concept behind LM involves locally approximating the loss function with a quadratic model. Consider the following least-squares loss function:</p> \[\mathcal{L} = \frac{1}{2}||l( \theta, y, \hat y)||_2^2 + \frac{1}{2} \lambda ||\theta||_2^2\] <p>Let’s expand \(l( \theta, y, \hat y)\) using a Taylor series and retain only the first two terms:</p> \[l \approx l(\theta_k) + \nabla l(\theta_k)^T (\theta - \theta_k) + \mathrm{h.o.t.}\] <p>Substituting this back into the loss function yields:</p> \[\begin{align} \mathcal{L} &amp;= \frac{1}{2}\big(l - \nabla l (\theta - \theta_k)\big)^T\big(l - \nabla l (\theta - \theta_k)\big) + \frac{1}{2}\lambda\theta^T \mathbb{I} \theta \\ &amp;=\frac{1}{2}\big(l^Tl + 2l^T \nabla l (\theta - \theta_k) + (\theta - \theta_k)^T \nabla l^T \nabla l (\theta - \theta_k)\big) + \frac{1}{2}\lambda\theta^T \mathbb{I} \theta \\ &amp; = \frac{1}{2} l^T l + l^T \nabla l(\theta - \theta_k) + \frac{1}{2}(\theta - \theta_k)\underbrace{(\nabla l^T \nabla l + \lambda \mathbb{I})}_{B} (\theta - \theta_k) \end{align}\] <p>From equation (3), it’s evident that the LM approximation of the Hessian matrix is given by \(B_k = \nabla l^T \nabla l + \lambda \mathbb{I}\). The regularization term \(\lambda \mathbb{I}\) ensures that \(B\) is always invertible, even when \(\nabla l^T \nabla l\) is singular. Therefore, one iteration of the LM method is expressed as:</p> \[\theta_{k+1} = \theta_k - \left(\nabla l^T \nabla l + \lambda \mathbb{I}\right)^{-1} \nabla \mathcal L(\theta_k)\] <h2 id="gradient-method">Gradient Method</h2> <p>Gradient Method (GM) or steepest descent method is one of the most widely used optimization techniques in machine learning. This method approximates the Hessian matrix with the identity matrix, weighted by the inverse of the learning rate \(\alpha\): \(B = \frac{1}{\alpha}\mathbb{I}\). Consequently, the optimization steps can be expressed as:</p> \[\theta_{k+1} = \theta_k - \alpha \nabla \mathcal L(\theta_k)\] <h2 id="quasi-newton-methods">Quasi-Newton Methods</h2> <p>Quasi-Newton Methods (QNM) approximate the Hessian matrix \(B_{k+1}\) based on the knowledge of \(B_k\), \(\nabla \mathcal L(\theta_k)\) and \(\nabla \mathcal L(\theta_{k+1})\). Among the various methods for determining the update to the Hessian matrix \(B_{k+1}\), one widely used and successful approach is the Broyden–Fletcher–Goldfarb–Shanno (BFGS) algorithm. In the BFGS algorithm, the curvature of the function is approximated using finite differences. In simpler terms, we choose the matrix \(B_{k+1}\) in a way that satisfies the secant condition:</p> \[B_{k+1} \left(\theta_{k+1} - \theta_k \right) = \nabla \mathcal L(\theta_{k+1}) - \nabla \mathcal L(\theta_{k}).\] <p>The rationale for selecting this condition is that the Hessian \(\nabla^2 \mathcal L(\theta_k)\) satisfies it as \(\theta_{k+1}\) approaches \(\theta_{k}\). Since multiple matrices can satisfy the secant condition, we can reasonably assume that \(B_{k+1}\) and \(B_k\) should be close to each other. Therefore, we choose \(B_{k+1}\) as the matrix closest to the previous Hessian approximation \(B_k\) among all matrices that satisfy the secant condition. To measure the proximity between \(B_{k}\) and \(B_{k+1}\), we can employ the concept of differential entropy between random variables with zero-mean Gaussian distributions \(\mathcal{N}(0, B_k)\) and \(\mathcal{N}(0, Z)\) which can be formulated as a <a href="https://en.wikipedia.org/wiki/Semidefinite_programming">semidefinite program</a>. This program (optimization problem) has an analytical solution in the form</p> \[\begin{align*} B_{k+1} &amp;= B_k - \frac{B_k s s^T B_k}{s^T B_k s} + \frac{y y^T}{s^T y}, \\ s &amp;= \theta_{k+1} - \theta_k, \\ y &amp;=\nabla \mathcal L(\theta_{k+1}) - \nabla \mathcal L(\theta_{k}). \end{align*}\] <p>Recall that the Hessian matrix is often dense and has dimensions \(n_\theta \times n_\theta\), where \(n_\theta\) represents the number of parameters we intend to optimize. Consequently, storing this matrix in memory can be memory-intensive. To address this issue, a variant of BFGS known as Limited-memory BFGS (L-BFGS) was developed. L-BFGS overcomes the memory challenge by having a linear memory requirement. In contrast to BFGS, which stores the Hessian approximation matrix \(B_k\), L-BFGS maintains a history of the previous \(m\) updates of both the parameters \(\theta\) and the gradient \(\nabla \mathcal L(\theta)\). This approach allows L-BFGS to implicitly represent the Hessian approximation using only a few vectors.</p> <h1 id="scalable-second-order-method-for-deep-learning">Scalable second-order method for deep learning</h1> <p>Second-order Clipped Stochastic Optimization (<a href="https://arxiv.org/pdf/2305.14342.pdf">Sophia</a>) goes one step further in reducing computational overhead by approximating the Hessian using a diagonal matrix. Additionally, it incorporates a clipping mechanism to control the maximum update size. This feature is essential because rapid changes in the landscape of the loss function could make the second-order information unreliable.</p> <p style="align: left; text-align:center;"> <img src="/assets/img/blog/sophia-so-vs-fo.png" alt="" width="50%"/> <div class="caption">Figure 3. Comparison of several popular optimizers on a toy example (<a href="https://arxiv.org/pdf/2305.14342.pdf" target="_blank">source</a>) </div> </p> <p>Concretely, Sophia estimates the diagonal entries of the Hessian of the loss using a mini-batch of examples every \(k\) steps. At each step, Sophia updates the parameters using an exponential moving average (EMA) of the gradient divided by the EMA of the diagonal Hessian estimate, which is then clipped by a scalar. Experiments on training LLM on GPT-2 dataset show that Sophia is twice as fast as the AdamW (Figure 4).</p> <p style="align: left; text-align:center;"> <img src="/assets/img/blog/sophia-llm.png" alt="" width="85%"/> <div class="caption">Figure 4. Comparison of AdamW, Lion and Sophia on training LLM on GPT-2 dataset (<a href="https://arxiv.org/pdf/2305.14342.pdf" target="_blank">source</a>) </div> </p> <h1 id="case-study">Case study</h1> <p>The test case was adopted from the <a href="https://kailaix.github.io/ADCME.jl/latest/optim/">Study on Optimizers</a>, which utilized a four-layer network consisting of 20 neurons per layer, all employing the hyperbolic tangent (tanh) activation function. This network was trained to fit the dataset \(\mathcal{D} = \{x_i, \sin(x_i) \}_{i=1}^{100}\), where \(x_i\) was sampled from a uniform distribution \(\mathcal{U}(0,1)\). The mean squared error (MSE) served as the loss function during training. The results on training using different optimizers are shown in the Figure 5.</p> <p style="align: left; text-align:center;"> <img src="/assets/img/blog/julia-optimizers.png" alt="" width="65%"/> <div class="caption">Figure 5. Comparison of Adam, BFGS and L-BFGS on a toy regression problem (<a href="https://kailaix.github.io/ADCME.jl/latest/optim/" target="_blank">source</a>) </div> </p> <p>The results from this toy example and findings from the Sophia paper clearly demonstrate that Newton-type optimization methods are significantly faster and yield lower loss values. This indicates the potential usefulness of second-order methods for training neural networks.</p> <h1 id="useful-resources">Useful resources</h1> <ol> <li><a href="https://github.com/jermwatt/machine_learning_refined#contact">Machine Learning Refined</a> is an excellent book with jupyter notebooks that visually explains zero-, first- and second-order optimization methods.</li> <li><a href="https://mlstory.org/index.html">Patterns, Predictions, and Actions</a> is another excellent book that explains the basics of the second-order methods.</li> </ol>]]></content><author><name></name></author><summary type="html"><![CDATA[Figure 1. The difference between the first-order and the second-order methods]]></summary></entry><entry><title type="html">Basic data augmentation methods for time series</title><link href="https://shamilmamedov.github.io/blog/2023/da-time-series/" rel="alternate" type="text/html" title="Basic data augmentation methods for time series"/><published>2023-07-30T09:00:00+00:00</published><updated>2023-07-30T09:00:00+00:00</updated><id>https://shamilmamedov.github.io/blog/2023/da-time-series</id><content type="html" xml:base="https://shamilmamedov.github.io/blog/2023/da-time-series/"><![CDATA[<p>In recent years, neural networks have shown promising results in tackling problems related to time series analysis: forecasting, classification, anomaly detection, and data imputation. Many of these achievements can be attributed to the availability of large-scale datasets. However, collecting such data can be challenging when dealing with time series.</p> <p>Data augmentation emerges as a method to increase the quantity of available data. Thereby, enhance the generalizability of models and reduce overfitting. In this article, we will explore fundamental data augmentation methods tailored specifically for time series analysis.</p> <p><em>Throughout the article, I will use the terms “time series” and “signal” interchangeably.</em></p> <h1 id="jitering">Jitering</h1> <p>Jittering, a simple yet popular data augmentation (DA) technique, involves adding noise to time series data. The method assumes that the data contain inherent noise, which is often the case when dealing with sensor data.</p> <p style="align: left; text-align:center;"> <img src="/assets/img/blog/jittering.png" alt="" width="60%"/> <div class="caption">Figure 1. An example of jittering i.e. adding noise to a signal </div> </p> <p>By adding noise to each time step, new samples can be generated, making it an effective approach to augment the dataset.Typically, Gaussian noise is used, where the mean and standard deviation define the magnitude and shape of the distortion, respectively. Applying jittering to a time series results in a new sample</p> \[x'(\epsilon) = \{x_1 + \epsilon_1, \dots, x_t + \epsilon_t, \dots, x_T + \epsilon_T \}\] <p>where \(\epsilon \sim \mathcal{N}(0, \sigma^2)\) represents the additive noise at each time step. Although, Gaussian noise is the most popular choice for a noise, other more complicated noise patterns such as spike, step-like trend and slope-like trend can also be employed. Overall, jittering is a straightforward and reliable method that often leads to improved model performance.</p> <h1 id="scaling">Scaling</h1> <p>Scaling changes the magnitude of certain steps in the time series while maintaining the overall shape of the signal. The transformed time series can be represented as:</p> \[x'(\alpha) = \{\alpha x_1, \dots, \alpha x_t, \dots, \alpha x_T \}\] <p>where \(\alpha &gt; 0\) defines the scale of the change. This scaling parameter can be defined using a Gaussian distribution with a mean of 1 and a standard deviation of \(\sigma\) – \(\mathcal{N}(1, \sigma^2)\). This method is analogous to the “resize” operation used in computer vision.</p> <p style="align: left; text-align:center;"> <img src="/assets/img/blog/scaling.png" alt="" width="60%"/> <div class="caption">Figure 2. An example of signal scaling </div> </p> <p>More advanced scaling method is magnitude warping. It involves applying variable scaling to different points of the signal. This technique uses a set of knots \(u = u_1,\dots,u_i\) to determine where the scaling transformation will be applied. These knots represent specific points in the time series where the scaling occurs and their values are generated using a normal distribution. The magnitude of scaling between the knots is determined by performing cubic spline interpolation on the knot values S(x) \(S(x)\). Mathematically, the magnitude warping can be expressed as follows:</p> \[x'(\alpha) = \{\alpha_1 x_1, \dots, \alpha_t x_t,\dots, \alpha_T x_T \}\] <p>where \(\alpha = \alpha_1,\dots,\alpha_i = S(x)\).</p> <p style="align: left; text-align:center;"> <img src="/assets/img/blog/mag_warping.png" alt="" width="60%"/> <div class="caption">Figure 3. An example of magnitude warping of a signal</div> </p> <p>Another scaling technique is time warping. While the concept behind time warping is similar to magnitude warping, the main difference between the two lies in the way they modify the signal. Time warping adjusts the temporal dimension of the signal by stretching or shortening the time (upsampling or downsampling) instead of modifying the magnitude at each step.</p> <p style="align: left; text-align:center;"> <img src="/assets/img/blog/time_warping.png" alt="" width="60%"/> <div class="caption">Figure 4. An example of time warping of a signal</div> </p> <p>Scaling methods can be very useful for medical data as people are different; the same health features can expressed differently.</p> <p>Scaling methods are indeed valuable in the context of medical data, especially due to the inherent variability among individuals. Applying scaling techniques can account for these differences and make models more robust.</p> <h1 id="time-slicing-window">Time slicing window</h1> <p>In time series analysis, slicing involves selecting a portion of each data sample to generate a new, distinct sample. When a section of the original data is cropped, it becomes a new sample; however, unlike image processing, maintaining all the essential features of the original data becomes challenging. The new sample can be represented as:</p> \[x'(W) = \{x_\phi,\dots,x_t,\dots x_{\phi + W} \}\] <p>where \(W\) denotes the size of the cropped window and \(\phi\) represents the initial point from where the slicing is initiated. One of the most important drawbacks of slicing the signal is that it can lead to invalid synthetic samples because it can cut off important features of the data. As a result, careful consideration is necessary when using slicing as a data augmentation method to avoid losing vital information during the process.</p> <p style="align: left; text-align:center;"> <img src="/assets/img/blog/window_slicing.png" alt="" width="60%"/> <div class="caption">Figure 5. An example of window slicing</div> </p> <h1 id="rotation">Rotation</h1> <p>Rotation can be applied to multivariate time series data by utilizing a rotation matrix with a specified angle. In univariate time series, the rotation is simply achieved by flipping the data. In the case of multivariate time series, a new rotated sample can be represented as follows:</p> \[x'(R) = \{R x_1, \dots, Rx_t, \dots, Rx_T \}\] <p>where \(R\) is the rotation matrix used to twist the data. The rotation angle \(\theta\) can be randomly sampled from a normal distribution. However, this algorithm is not commonly employed in time series analysis as rotating a time series sample may result in the loss of important signal features.</p> <p style="align: left; text-align:center;"> <img src="/assets/img/blog/rotation.png" alt="" width="60%"/> <div class="caption">Figure 6. An example of rotation applied to univariate signal</div> </p> <p>Be aware that applying rotation can sometimes worsen the model performance as it might change the physics of data. For example, in physical systems applying rotation might change the gravity vector yielding physically inconsistent new sample — objects instead of falling under gravity might levitate or move randomly.</p> <p>It is crucial to be cautious when applying rotation to time series data, as it may negatively impact the model’s performance by introducing random features. For instance, in physical systems, applying rotation might lead to changes in the gravity vector, resulting in physically inconsistent new samples. Objects that should fall under gravity might appear to levitate or move randomly, introducing unrealistic behavior.</p> <h1 id="permutation">Permutation</h1> <p>Shuffling different time slices of data in order to perform DA is a method that generates new data patterns. The main problem of applying permutation is that it does not preserve time dependencies; thus, it can lead to invalid samples. Mathematically, new permuted sample can be defined as</p> \[x'(w) = \{x_i,\dots,x_{i+w}, \dots, x_j, \dots, x_{j+w}, \dots, x_k, \dots, x_{k+w} \}\] <p>where \(i,j,k\) represents the first index slice of each window, so that each is selected exactly once, and \(w\) denotes the window size.</p> <p style="align: left; text-align:center;"> <img src="/assets/img/blog/permutation.png" alt="" width="60%"/> <div class="caption">Figure 7. An example of signal permutation: shuffling different window slices </div> </p> <h1 id="channel-permutation">Channel permutation</h1> <p>Changing the position of different channels in multi-dimensional data is a common practice. In computer vision, it is quite popular to swap the RGB channels to perform DA. With respect to time series, channel permutation can be applied as long as each channel of the data is still valid. The channel permutation algorithm, for multidimensional data such as \(x=\{\{x_{11},\dots,x_{1T}\}, \dots, \{x_{c1},\dots,x_{cT}\} \}\) where \(c\) is the number of channels, is given by</p> \[x=\{\{x_{\sigma(1)1},\dots,x_{\sigma(1)T}\}, \dots, \{x_{\sigma(c)1},\dots,x_{\sigma(c)T}\} \}\] <p>where \(\sigma: \{1,\dots,c \} \rightarrow \{1,\dots,c\}\) is the used permutation of the channels.</p> <p style="align: left; text-align:center;"> <img src="/assets/img/blog/channel_permutation.png" alt="" width="60%"/> <div class="caption">Figure 8. An example of channel permutation</div> </p> <h1 id="wrap-up">Wrap up</h1> <p>In time series analysis, high-quality data is often limited. One simple approach to address this issue is by generating new data through the augmentation of existing samples.</p> <p>In this article, we have introduced you to fundamental methods for augmenting time series data. Some of these techniques resemble those commonly used in computer vision, while others are specifically tailored for time series analysis, such as time and magnitude warping.</p> <p>The most straightforward and safe data augmentation method is <strong>jittering</strong>, which likely explains its popularity. However, you need to be careful when employing other augmentation methods; domain knowledge might be very useful for selecting the appropriate augmentation method. For instance, <strong>rotation</strong> may seem like a harmless augmentation, but in physical systems, it alters the gravity vector. As a result, the augmented dataset could negatively impact a model trained to predict the motion of objects affected by gravity.</p> <p><strong>Scaling methods</strong> might prove effective in medical applications, whereas <strong>permutation</strong> methods may be beneficial for classification tasks but might not significantly improve regression models. In the next article, we will explore more advanced augmentation techniques, which involve discovering hidden models that generated the existing data and subsequently using these models to generate new data. Yes, we are referring to variational autoencoders and generative adversarial networks.</p> <h1 id="libraries">Libraries</h1> <ol> <li><a href="https://github.com/arundo/tsaug">Tsaug</a> — python library for time series data augmentation</li> <li><a href="https://timeseriesai.github.io/tsai/">tsai</a> — popular python library for time series modeling; it has a module for data augmentation</li> </ol> <h1 id="references">References</h1> <ol> <li> <p>Images are taken from <a href="https://arxiv.org/abs/2206.13508">Talavera, Edgar, et al. “Data augmentation techniques in time series domain: A survey and taxonomy.” <em>arXiv preprint arXiv:2206.13508</em> (2022).</a></p> </li> <li> <p><a href="https://arxiv.org/abs/2002.12478">Wen, Qingsong, et al. “Time series data augmentation for deep learning: A survey.” <em>arXiv preprint arXiv:2002.12478</em> (2020).</a></p> </li> </ol>]]></content><author><name></name></author><summary type="html"><![CDATA[In recent years, neural networks have shown promising results in tackling problems related to time series analysis: forecasting, classification, anomaly detection, and data imputation. Many of these achievements can be attributed to the availability of large-scale datasets. However, collecting such data can be challenging when dealing with time series.]]></summary></entry><entry><title type="html">Neural ODE</title><link href="https://shamilmamedov.github.io/blog/2023/node/" rel="alternate" type="text/html" title="Neural ODE"/><published>2023-06-24T09:00:00+00:00</published><updated>2023-06-24T09:00:00+00:00</updated><id>https://shamilmamedov.github.io/blog/2023/node</id><content type="html" xml:base="https://shamilmamedov.github.io/blog/2023/node/"><![CDATA[<p style="align: left; text-align:center;"> <img src="/assets/img/blog/damped-pendulum-vector-field.png" alt="" width="100%"/> <div class="caption">Figure 1. A vector field of a damped pendulum </div> </p> <p>Differential equations serve as the natural language of physics and nature. Remember back in school when you were taught Newton’s Second Law of Motion: \(F = ma\)? The acceleration \(a\), represents the second derivative of the position \(x\). Consequently, we have \(F = m \ddot x\), which is a second-order ordinary differential equation (ODE). Differential equations find wide application in various fields, including biology, economics, and sociology, as they can effectively model numerous phenomena.</p> <p>On the other hand, machine learning and other data-driven methods have demonstrated their ability to successfully predict behaviors of complex systems. The question arises: How can we combine machine learning with differential equations to construct more robust models for understanding and representing natural phenomena?</p> <h1 id="ordinary-differential-equations-recap">Ordinary differential equations recap</h1> <div style="display: flex; flex-wrap: wrap;"> <div style="width: 50%;"> In general, a differential equation can be expressed in the form: $$ \frac{d}{dt}z(t) := \dot z(t) = f\left(t,z(t), \theta\right) $$ Here, \(z(t)\) represents the state, \(f(\cdot)\) denotes the vector field, \(t\) corresponds to time, and \(\theta\) represents the parameters. An example of the vector field is shown in the Figure 1. Essentially, an ODE models the rate of change of variables. For instance, consider the differential equations governing a simple pendulum shown in the figure 2: </div> <div style="width: 50%;"> <p style="align: left; text-align:center;"> <img src="/assets/img/blog/pendulum-drawing.png" alt="" width="45%"/> <div class="caption">Figure 2. A drawing of a simple pendulum</div> </p> </div> </div> \[\dot z(t) = \begin{bmatrix} z_2(t)\\ -\frac{g}{L} \sin(z_1(t)) \end{bmatrix}\] <p>In this case, \(z_1(t):=\theta\) denotes the angle of the pendulum, \(z_2(t):=\dot \theta\) represents the angular velocity, \(g\) denotes the gravitational constant, and \(L\) stands for the length of the pendulum. Intuitively, pendulum ODE describes how the angle and angular velocities change.</p> <p>When working with differential equations, it is crucial to specify the initial state. Without knowing the initial condition \(z(t_0)\), it becomes impossible to solve the differential equation aka to integrate it. It is worth noting that the majority of real-world differential equations do not have analytical solutions. However, numerical methods have been developed to approximate solutions at discrete points. These methods involve integrating the equation over a given interval</p> \[z(t_1) = z(t_0) + \int_{t_0}^{t_1} f(t, z(t), \theta)\ dt = \text{ODESolve}(z(t_0), f, \theta, t_0, t_1)\] <p>In the following subsections, we will explore two simple methods that provide a glimpse into solving ODEs using numerical techniques and quickly discuss advanced methods.</p> <h2 id="euler-methods">Euler Methods</h2> <div style="display: flex; flex-wrap: wrap;"> <div style="width: 50%;"> One of the simplest methods for numerical integration is Euler's method. It is derived from the basic definition of the tangential approximation of the gradient at a point $$ \frac{dz(t)}{dt} \approx \frac{z(t+\Delta t) - z(t)}{\Delta t} $$ where \(\Delta t\) is a fixed step-size. By rearranging this expression, we obtain the final form of the Euler integrator </div> <div style="width: 50%;"> <p style="align: left; text-align:center;"> <img src="/assets/img/blog/euler-method.png" alt="" width="45%"/> <div class="caption">Figure 3. Visualization of the Euler method [1]</div> </p> </div> </div> \[z(t+\Delta t) = z(t) + \Delta t \frac{dz(t)}{dt} = z(t) + \Delta t \ f\big(t, z(t), \theta \big)\] <p>To integrate an ODE using Euler method, we begin with an initial time \(t_0\), initial state \(z(t_0)\) and a step-size \(\Delta t\). We then iteratively compute the trajectory of the ODE until we reach final time \(t_N := t_0 + N \Delta t\)</p> \[\begin{align*} z(t_1) = z(t_0) + \Delta t\ f(t_0, z(t_0), \theta),\quad t_1 = t_0 + \Delta t \\ z(t_2) = z(t_1) + \Delta t\ f(t_1, z(t_1), \theta),\quad t_2 = t_1 + \Delta t \\ \dots \\ z(t_N) = z(t_{N-1}) + \Delta t\ f(t_{N-1}, z(t_{N-1}), \theta),\quad t_N = t_{N-1} + \Delta t \end{align*}\] <p>One intuition behind the Euler method is that we are evolving the trajectories by iteratively taking small steps in the direction of the slope.</p> <h2 id="runge-kutta-methods">Runge-Kutta Methods</h2> <p>Despite being easy to understand and implement, the Euler method is often not used in practice due to its low accuracy. Instead, a more commonly employed method that strikes a balance between computational efficiency and accuracy is the fourth-order Runge-Kutta (RK4) method. This method involves computing the state at the next time step by taking four intermediate steps</p> \[z(t + \Delta t) = z(t) + \frac{1}{6} \Delta t(k_1 + k_2 + k_3 + k_4)\] <p>where</p> <div style="display: flex; flex-wrap: wrap;"> <div style="width: 50%;"> <p> $$ \begin{align*} k_1 = f(t, z(t), \theta) \\ k_2 = f(t + \frac{\Delta t}{2}, z(t) + \Delta t\ \frac{k_1}{2}, \theta) \\ k_3 = f(t + \frac{\Delta t}{2}, z(t) + \Delta t\ \frac{k_2}{2}, \theta) \\ k_4 = f(t + \Delta t, z(t) + \Delta t\ k_3, \theta) \end{align*} $$ Derivation of the RK4 equations is out of scope of this article. I will only quickly mention that it is based on the Taylor expansion of both \(z(t + \Delta t)\) and \(f(t+\Delta t, z + \Delta z)\). </p> Integrating an ODE with RK4 is similar to the Euler method and to any other method with fixed step size: define initial time \(t_0\) initial state \(z(t_0)\) step size \(\Delta t\) and the number of steps \(N\) then in a for loop we iteratively compute the state \(z(t)\) at discrete moments of time \(t_0, t+\Delta t, \dots , t+ N \Delta t\). </div> <div style="width: 50%;"> <p style="align: left; text-align:center;"> <img src="/assets/img/blog/RK4-method.png" alt="" width="80%"/> <div class="caption">Figure 4. Visualization of the RK4 method [2]</div> </p> </div> </div> <h2 id="variable-step-size-methods">Variable step-size methods</h2> <p>To achieve greater accuracy than RK4, we can utilize variable step solvers. These solvers dynamically adjust the step-size to meet specified absolute and relative tolerances. One prominent example of such integrators is the Dormand-Prince method (DP45). The DP45 method determines the appropriate step-size by estimating the integration error, which is computed by comparing the results of the 5th and 4th order Runge-Kutta methods. However, a trade-off for this increased accuracy is the additional computational time required, as the number of steps needed for ODE integration cannot be predetermined.</p> <h1 id="neural-differential-equations">Neural Differential equations</h1> <p>Now that we have a solid understanding of what ODEs are and how to solve them, we can explore the process of obtaining the ODE itself. While it may be relatively straightforward to derive the vector field \(f\) for simple systems like a pendulum, tackling complex systems such as robots or virus spread rates requires extensive domain knowledge. Furthermore, even if we manage to obtain the vector field, ensuring the accuracy of the parameters \(\theta\) within that vector field can be challenging. This is due to the numerous assumptions and simplifications made when formulating physical laws (consider the ideal gas assumption, for instance).</p> <p>If we are provided with input-output data, we can employ a function approximator to estimate the underlying vector field \(f\). One popular choice for this approximator is a neural network, leading to the concept of Neural Ordinary Differential Equations (Neural ODEs):</p> \[\dot z(t) = NN\big(t, z(t), \theta_{NN}\big)\] <h2 id="comparison-to-resnets">Comparison to Resnets</h2> <p>When we apply the Euler method to integrate a Neural ODE, we obtain an equation that closely resembles a ResNet</p> \[z(t+\Delta t) = z(t) + \Delta t \ NN(t, z(t), \theta_{NN})\] <p>with the only difference being the scaling coefficient \(\Delta t\). If we allow the neural network \(NN(\cdot)\) to incorporate the \(\Delta t\) parameter \(\tilde{NN}(\cdot) = \Delta t\ NN(\cdot)\), the Neural ODE integrated with the Euler method effectively becomes a ResNet.</p> \[z(t+\Delta t) = z(t) +\tilde{NN}(t, z(t), \theta_{NN})\] <p style="align: left; text-align:center;"> <img src="/assets/img/blog/Resnet-ODEnet.png" alt="" width="55%"/> <div class="caption">Figure 5. Comparison between ResNet and an ODE Network [3]</div> </p> <p>Earlier we learned that the Euler integrator is outperformed by other integration methods like the RK4 or variable step integrators. Therefore, utilizing Neural ODEs with these improved integrators can lead to more accurate and reliable models than ResNets. Furthermore, Neural ODEs can be viewed as infinite-dimensional networks: ResNets provide a solution at a discrete points and have low accuracy, but Neural ODEs with the adaptive step-size has higher accuracy and smooth vector field as shown in the Figure 4. If we want to get the same accuracy with the ResNets we need to make them very deep.</p> <h2 id="training-and-gradients">Training and gradients</h2> <p>If you’re already wondering about training these beasts called Neural ODEs and the intimidating concept of viewing them as infinite depth ResNets, fear not! Computing gradients for Neural ODEs is actually quite efficient and requires minimal memory.</p> <p>Let’s say we have a dataset \(\mathcal{D} = \{x_i, y_i\}\) where \(x\) represents the input and \(y\) represents the target. For example, let \(x\) be the angle and angular velocities of the pendulum and \(y\) be the same quantities but after 1 second. Our goal is to train a Neural ODE to predict the target using a loss function \(\mathcal{L}(\hat y, y)\). We can express the predicted output \(\hat y_i\) as:</p> \[\hat y_i := z(t_1) = \text{ODESolve}(z(t_0), NN, \theta_{NN}, t_0, t_1)\] <p>Here, \(\text{ODESolve}\) can be any integrator, \(y(t_0) := x_i\) represents the initial state of our Neural ODE, and \(t_0\) and \(t_1\) are the initial and final integration times, respectively. When using variable step integrators, we may perform numerous intermediate computations, resulting in a large computational graph. Consequently, performing backpropagation through this graph can be computationally expensive and slow.</p> <p style="align: left; text-align:center;"> <img src="/assets/img/blog/adjoint-integration.png" alt="" width="60%"/> <div class="caption">Figure 6. Backpropagation of a Neurtal ODE [3]</div> </p> <p>However, it turns out that obtaining the gradients of \(\hat y_i\) with respect to the states \(z(t)\), parameters \(\theta_{NN}\), and time \(t\) is surprisingly straightforward. We simply need to integrate an additional ODE (backward in time) that provides all these gradients. This powerful technique is known as the adjoint method. While the derivations can be somewhat involved, if you want to dive into math here are two excellent sources: <a href="https://vaipatel.com/deriving-the-adjoint-equation-for-neural-odes-using-lagrange-multipliers/">the method of Lagrange multipliers</a> and t<a href="https://feicheung2016.medium.com/neural-ode-from-scratch-and-revisit-backward-propagation-4fa050649400">he method described in the original paper.</a></p> <p>In this article as an example we considered regression problem, but Neural ODE can also be used for classification. For those task Neural ODE has to make different classes linearly separable at the end of the integration.</p> <h2 id="pros-and-cons">Pros and cons</h2> <p>According to the <a href="https://arxiv.org/abs/1806.07366">seminal paper,</a> Neural ODEs offer several advantages over deep ResNets. They allow for more memory-efficient training and require fewer parameters. Additionally, the backpropagation process is more computationally efficient with Neural ODEs.</p> <p>Neural ODEs are particularly well-suited for time series data, especially when the dataset is irregularly sampled, which is often the case. When dealing with non-uniform, classical methods like RNNs require special treatment. In contrast, Neural ODEs naturally handle non-uniform data by adapting the time grid of the integrator.</p> <p>From a personal perspective, training Neural ODEs is slower compared to training RNNs. In case of uniform data, use RNNs for their efficiency.</p> <h2 id="software">Software</h2> <p>Nowadays there are many libraries that facilitate the training of Neural ODEs. If you prefer working with PyTorch, use either <a href="https://github.com/rtqichen/torchdiffeq">torchdiffeq</a> or <a href="https://github.com/DiffEqML/torchdyn">torchdyn</a>. These libraries provide comprehensive functionalities for building and training Neural ODE models within the PyTorch framework. On the other hand, if you opt for JAX, I highly recommend <a href="https://github.com/patrick-kidger/diffrax">diffrax</a>.</p> <h1 id="resources">Resources</h1> <p>[1] <a href="https://en.wikipedia.org/wiki/Euler_method">Wikipedia article on Euler method</a></p> <p>[2] <a href="https://en.wikipedia.org/wiki/Runge%E2%80%93Kutta_methods">Wikipedia article on Runge-Kutta methods</a></p> <p>[3] <a href="https://arxiv.org/abs/1806.07366">Seminal paper on neural ordinary differential equations</a></p>]]></content><author><name></name></author><summary type="html"><![CDATA[Figure 1. A vector field of a damped pendulum]]></summary></entry><entry><title type="html">Learning latent dynamics from partial observations</title><link href="https://shamilmamedov.github.io/blog/2023/recognition-models/" rel="alternate" type="text/html" title="Learning latent dynamics from partial observations"/><published>2023-04-24T09:00:00+00:00</published><updated>2023-04-24T09:00:00+00:00</updated><id>https://shamilmamedov.github.io/blog/2023/recognition-models</id><content type="html" xml:base="https://shamilmamedov.github.io/blog/2023/recognition-models/"><![CDATA[<p>Imagine you’re trying to predict the behavior of a complex system, like a weather pattern, a financial market or a robot. In an ideal world, you would have access to all of the relevant data needed to accurately model the system (full state measurement). However, in reality, we rarely have access to a full state only to partial observations (outputs) which might be a subset of states or some nonlinear transformation of states. This presents a challenge for machine learning algorithms that rely on full state measurement.</p> <p>In this post, we’ll explore several methods for learning system dynamics from partial observations. We’ll discuss why this problem is important, and why it’s relevant to real-world applications like predicting weather, stock prices or robot behavior. By the end of this post, you’ll have a better understanding of the challenges involved in learning system dynamics from partial observations, and the methods that are currently being used to tackle this problem.</p> <h1 id="problem-formulation">Problem formulation</h1> <p>To understand how we can learn system dynamics from partial observations, we need to define the problem more precisely. Let’s start with the ground truth nonlinear discrete dynamics, which can be defined by the following difference equation:</p> \[x_{k+1} = F\big(x_k, u_k, \theta_{r}\big)\] <p>where \(x_k = x(t_k)\) is the vector of states of the system at time \(t_k\), \(u_k\) is the vector of external inputs and \(\theta_r\) is the vector of true parameters of the system. Let \(y_k\) represent noisy observations (measurements) of the system</p> \[y_k = H\big(x_k\big) + \nu_k\] <p>where \(H(x_k)\) is the state-to-observation map and \(\nu_k\) is a noise. As an example, imagine we need to learn a robot dynamics shown in Figure 1. The states of the robot are joint positions and velocities. But assume that the data are external inputs (joint torques) and positions of some keypoints measured using a camera while the robot is moving.</p> <p style="align: left; text-align:center;"> <img src="/assets/img/blog/panda-dynamics-example.png" alt="" width="90%"/> <div class="caption">Figure 1. Robot as an example of partially observable system</div> </p> <p>Given these noisy measurements, we would like to learn an approximation of the original system dynamics \(\hat z_{k+1} = \hat F(\hat z_k, u_k, \theta_a)\) with \(\hat F(\cdot)\) being the approximation of the original state transition map \(F(\cdot)\) and \(\theta_a\) being the parameters of the approximate transition map. If we know the dimension of the original state \(x\), then we can choose \(z\) to be of the same size. Otherwise — if we don’t know the dimension or want to find a lower dimensional approximation of the map \(F(\cdot)\) — we can choose the dimension of \(z\) arbitrarily to a degree that it can accurately predict outputs \(y.\)</p> <p style="align: left; text-align:center;"> <img src="/assets/img/blog/rnn-schematics.png" alt="" width="60%"/> <div class="caption">Figure 2. Working principle of an RNN</div> </p> <p>For the sake of simplicity, lets use recurrent neural networks (RNNs) for approximating the dynamics. Figure 2 shows schematically the working principle of the vanilla RNN, where each rhomb is an RNN block. In a nutshell, RNN takes an input \(u_k\) and state \(\hat z_k\) and spits out the next state \(\hat z_{k+1}\). Mathematically spaeking, vanilla RNN propagates dynamics by</p> \[\hat z_{k+1} = \tanh(W_{\hat z} \hat z_k + W_u u_k + b).\] <p>To sum up, we are interested in learning the model of a complex dynamical system from partial observations. The model should accurately predict \(N\) next states/observations of the system: \(z_{k+1}\), \(z_{k+2}\), \(\dots\), \(z_{k+N+1}\). In essence, the problem we trying to solve boils down to finding an initial state \(z_0\) that will be used by RNN to propagate the dynamics and state-to-observation transformation \(\hat H(\cdot)\). Now, lets dive into several methods that have been proposed to solve this problem.</p> <h1 id="autoencoders">Autoencoders</h1> <p>A common approach in machine learning for solving such problems is autoencoders. Here our input feature vector \(h\) for the encoder is a sequence of output and input measurements. For simplicity, let’s choose \(h_k = \left(y_k; u_k\right)\). The encoder—a multilayer perceptron (MLP)—takes the input vector \(h_k\) and outputs the latent state \(z_k = \phi\left(h_k\right)\). Given the latent state and a sequence of inputs \(U = [u_k\ u_{k+1} \dots u_{k+N}]\), the RNN propagates the dynamics and returns a sequence of states \(\hat{z}_{k+1},\ \hat{z}_{k+2},\ \dots,\ \hat{z}_{k+N}\). The decoder—another MLP—takes states and maps them into a sequence of outputs \(\hat{y}_{k+1},\ \hat{y}_{k+2},\ \dots,\ \hat{y}_{k+N}\).</p> <p style="align: left; text-align:center;"> <img src="/assets/img/blog/autoencoder-approach.png" alt="" width="80%"/> <div class="caption">Figure 3. Autoencoder based latent dynamics learning</div> </p> <p>The loss function of the whole end-to-end learning is a combination of several losses:</p> <ul> <li>encoder-decoder loss which measures how well the enocder-decoder pair work together</li> </ul> \[\mathcal{L}_1= \sum_{k=1}^{N} ||h_k - \psi(\phi(h_k)) ||_2^2\] <ul> <li>state reconstruction loss which measures if encoded latent state matches the dynamics of the system</li> </ul> \[\mathcal{L}_2 = \sum_{j=1}^{N} ||z_{k+j} - \hat z_{k+j}||_2^2\] <ul> <li>Output prediction loss which measures how well the dynamics approximates the true dynamics</li> </ul> \[\mathcal{L}_3 = \sum_{j=1}^N||h_{k+j} - \psi(\hat z_{k+j})||\] <p>The total loss function is the weighted sum of the individual losses: \(\mathcal{L} = \alpha \mathcal{L}_1 + \beta \mathcal{L}_2 + \gamma \mathcal{L}_3\) . One paper where such an approach has been used in combination with <a href="https://en.wikipedia.org/wiki/Sparse_identification_of_non-linear_dynamics">SINDY</a> is <a href="https://arxiv.org/abs/2201.05136">link</a>. Check it out for more detail.</p> <h1 id="rnn-encoders">RNN Encoders</h1> <p>Another machine learning approach is to use an RNN as an encoder to learn the latent dynamics. In this method, we take a sequence of observation and external input pairs \((y_{k}, u_{k}),\ (y_{k+1}, u_{k+1}),\ \dots, \ (y_{k+M}, u_{k+M})\) and feed it to an RNN backwards in time, where the final state of the RNN is the sought-after state \(z_k\). In a probabilistic setting, the final state of the RNN represents the mean and covariance of the distribution \(z_k \sim \mathcal{N}(\mu_k, \Sigma_k)\). Typically, the RNN encoders state is initialized with a zero vector.</p> <p style="align: left; text-align:center;"> <img src="/assets/img/blog/RNN-encoder.png" alt="" width="85%"/> <div class="caption">Figure 4. RNN encoder based latent dynamics learning</div> </p> <p>If you are familiar with sequence-to-sequence modeling, you may recognize the RNN encoder architecture from machine translation. In this context, the RNN encoder provides “context” for the RNN decoder, which generates a translation based on it.</p> <p>This scheme works well due to the stability of dynamical systems. Stable dynamical systems “forget” their initial state and converge to a stationary point. Therefore, it’s a good idea to choose a relatively large input sequence MM to give it time to converge. RNN encoders have been used extensively in learning latent dynamics with neural ordinary differential equations, for example in <a href="https://arxiv.org/abs/1806.07366">this</a> and <a href="https://arxiv.org/abs/1907.03907">this</a> papers.</p> <h1 id="learning-the-initial-state">Learning the initial state</h1> <p>The system identification community has developed its own tools for learning latent dynamics, and one of the simplest methods is to make the initial state an optimization variable and eliminate the need for an encoder. This approach is often used for grey box system identification, where the system structure \(F(x_k, u_k, \theta_r)\) and the state-to-output map \(H(x_k)\) are known but the parameters \(\theta_r\) are not. However, this method can also be used for more generic (black box) model architectures such as RNNs. Nevertheless, making the initial state an optimization variable increases the number of optimization variables, especially when using mini-batch optimization. Therefore, it only makes sense to learn the initial state when trying to predict long horizons and using batch optimization. This method has been used in various works, including the <a href="https://github.com/meco-group/nlgreyfast">work</a> by my colleague in <a href="https://www.mech.kuleuven.be/en/pma/research/meco">MECO</a> Andras.</p> <p style="align: left; text-align:center;"> <img src="/assets/img/blog/learn-initial-state.png" alt="" width="65%"/> <div class="caption">Figure 5. Learning latent state for latent dynamics learning</div> </p> <h1 id="kkl-encoder">KKL encoder</h1> <p>The majority of control policies for robots, planes, or chemical plants rely on the latent state to compute the action. Control engineers have developed algorithms called state estimators or observers to infer latent states from partial observations. The most famous among them are <a href="https://en.wikipedia.org/wiki/Kalman_filter">the Kalman filter</a> and its variations, such as <a href="https://en.wikipedia.org/wiki/Extended_Kalman_filter">the extended Kalman filter</a> and <a href="https://quantdare.com/beyond-linear-ii-the-unscented-kalman-filter/">the unscented Kalman filter</a>. However, most state estimation algorithms heavily rely on the latent dynamical model of the system. In our setting, using classical state observers would lead to a chicken-and-egg problem: we need to infer the latent state from partial observations to learn the latent dynamical model, but we need the latent dynamical model to do so.</p> <p>Among the few state estimation algorithms that do not heavily rely on an accurate dynamical model is the Kazantzis-Kravaris Luenberger (KKL) observer. The KKL observer separates the latent dynamics \(z_{k+1} = \hat F(z_k, u_k, \theta_a)\) from the observer dynamics and assumes linear dynamics for the observer, where the state of the KKL observer, denoted by xi, evolves according to the following equation:</p> \[\xi_{k+1} = D \xi_k + G \begin{bmatrix} y_k \\ u_k \end{bmatrix}\] <p>where \(D\) is a stable state matrix with eigenvalues \(-1 &lt; \lambda_i &lt; 1\). The stability requirement guarantees that no matter how we initialize \(\xi\), after a sufficiently long time, the observer will converge and “forget” its initial state. The KKL observer is able to separate observer dynamics from latent dynamics because there exists a smooth invertible map \(\mathcal{T}\) that goes from our latent state \(z\) to the observer state \(\xi\) and back. Unfortunately, there is no ready-to-use recipe for finding such a map. In practice, we can think of the map \(\mathcal{T}\) and its inverse \(\mathcal{T}^*\) as an autoencoder that is jointly learned together with the latent dynamics. The difference between the purely autoencoder approach and the KKL observer approach is that the input of the encoder is the KKL observer state instead of a sequence of observations and external inputs (as shown in Figure 6). Check out <a href="https://arxiv.org/abs/2205.12550">this</a> paper, if you want to learn more about KKL encoder method.</p> <p style="align: left; text-align:center;"> <img src="/assets/img/blog/KKL-encoder.png" alt="" width="95%"/> <div class="caption">Figure 6. KKL encoder based latent dynamics learning</div> </p> <h1 id="conclusions">Conclusions</h1> <p>In real life, we often have to train models to predict the behavior of complex dynamic systems based on partial observations. To train a model with hidden variables, we need to somehow estimate/reconstruct the initial hidden state, and then propagate the hidden state using the chosen architecture and sequence of (external) inputs. There are various methods for estimating the initial hidden state. Perhaps the simplest method is to make the initial state an optimization variable. This method has one major drawback: depending on the type of learning (batch vs mini-batch) and the duration of the dynamics propagation, the number of optimization variables can grow significantly.</p> <p>The most common method is probably the autoencoder, where the encoder takes a sequence of partial observations and external inputs as input and returns the hidden state. The decoder, in turn, takes the hidden state as input and tries to reconstruct the encoder input. The next two methods - RNN and KKL encoders - are dynamic: they take a partial observation and an external input as input, propagate the dynamics back in time to find the initial hidden state.</p> <p>In <a href="https://arxiv.org/abs/2205.12550">this</a> article, it is shown that the difference between different approaches is not very significant for modeling the hidden dynamics of an exoskeleton. Therefore, in practice, I would first implement an autoencoder. If the model quality is unsatisfactory, I would switch to dynamic encoders.</p>]]></content><author><name></name></author><summary type="html"><![CDATA[Imagine you’re trying to predict the behavior of a complex system, like a weather pattern, a financial market or a robot. In an ideal world, you would have access to all of the relevant data needed to accurately model the system (full state measurement). However, in reality, we rarely have access to a full state only to partial observations (outputs) which might be a subset of states or some nonlinear transformation of states. This presents a challenge for machine learning algorithms that rely on full state measurement.]]></summary></entry><entry><title type="html">Robot dynamics (three different ones)</title><link href="https://shamilmamedov.github.io/blog/2023/robot-dynamics/" rel="alternate" type="text/html" title="Robot dynamics (three different ones)"/><published>2023-03-30T09:00:00+00:00</published><updated>2023-03-30T09:00:00+00:00</updated><id>https://shamilmamedov.github.io/blog/2023/robot-dynamics</id><content type="html" xml:base="https://shamilmamedov.github.io/blog/2023/robot-dynamics/"><![CDATA[<p style="align: left; text-align:center;"> <img src="/assets/img/blog/robot-dynamics.png" alt="" width="40%"/> <div class="caption">A schematic representation of a two degree of freedom robot</div> </p> <p>As a roboticist, understanding robot dynamics is essential for designing fast, agile trajectories and controlling potentially unstable, complex robots. In this post, we will explore three types of robot dynamics at a high level and demonstrate how to compute them using the <a href="https://stack-of-tasks.github.io/pinocchio/">Pinocchio</a> library, which is an efficient implementation of rigid robot dynamics algorithms.</p> <h1 id="inverse-dynamics">Inverse dynamics</h1> <p>Inverse dynamics is a crucial problem in robotics, necessary for motion control systems, trajectory design, and optimization. It involves finding the forces required to produce a given acceleration in a rigid-body system that consists of bodies that do not deform or change shape during motion. To represent inverse dynamics, we can use the equation:</p> \[\tau = \mathrm{ID}(model,\ q,\ \dot q,\ \ddot q) = M(q)\ddot q + C(q, \dot q) \dot q + g (q)\] <p>Here, \(model\) is the model description of the robot that contains kinematics, which are transformations between joints, and dynamical parameters like masses of links, their inertias, and the center of mass. \(q\), \(\dot q\), \(\ddot q\) are vectors of joint positions, velocities, and accelerations, while \(\tau\) is the vector of joint torques. \(M(q)\) is the position-dependent inertia matrix, \(C(q, \dot q)\) is the matrix of Centrifugal and Coriolis forces, and \(g(q)\) is the vector of gravitational forces.</p> <p>The recursive Newton-Euler algorithm (RNEA) is the most efficient algorithm for computing inverse dynamics. It consists of two recursions: forward and backward. During the forward recursion, we calculate the velocity and acceleration of each body in the tree and the forces required to produce these accelerations. During the backward recursion, we calculate the forces transmitted across the joints from the forces acting on the bodies and the generalized forces at the joint.</p> <p>Computing inverse dynamics in Pinocchio is straightforward. The following code snippet demonstrates how to do it:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">pinocchio</span> <span class="k">as</span> <span class="n">pin</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="n">urdf_path</span> <span class="o">=</span> <span class="sh">''</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">pin</span><span class="p">.</span><span class="nf">buildModelFromUrdf</span><span class="p">(</span><span class="n">urdf_path</span><span class="p">)</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="nf">createData</span><span class="p">()</span>

<span class="n">q</span> <span class="o">=</span> <span class="n">pin</span><span class="p">.</span><span class="nf">randomConfiguration</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
<span class="n">v</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">uniform</span><span class="p">(</span><span class="o">-</span><span class="n">np</span><span class="p">.</span><span class="n">pi</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="n">pi</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">nv</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
<span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">uniform</span><span class="p">(</span><span class="o">-</span><span class="n">np</span><span class="p">.</span><span class="n">pi</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="n">pi</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">nv</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>

<span class="n">tau</span> <span class="o">=</span> <span class="n">pin</span><span class="p">.</span><span class="nf">rnea</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">a</span><span class="p">)</span>
</code></pre></div></div> <h1 id="forward-dynamics">Forward dynamics</h1> <p>Forward dynamics is the problem of finding the acceleration of a rigid-body system in response to given applied forces. It is mainly used for simulation. The equation that represents forward dynamics is:</p> \[\ddot q = \mathrm{FD}(model, q, \dot q, \tau) = M(q)^{-1}\big(\tau - C(q, \dot q)\dot q - g(q)\big)\] <p>There are two methods to calculate forward dynamics: the slow system level method and the fast propagation method. In the following two subsections, we will discuss each of them.</p> <h2 id="slow-system-level-method">Slow system level method</h2> <p>The system level method involves three steps:</p> <ol> <li>Calculate the bias force \(h(q,\dot q) = C(q, \dot q) \dot q + g(q)\);</li> <li>Calculate the inertia matrix \(M(q)\);</li> <li>Solve a system of linear equations for \(\ddot q\).</li> </ol> <p>Steps 1 and 2 can be accomplished using the inverse dynamics algorithm: \(h(q, \dot q) = \mathrm{ID}(model, q, \dot q, 0)\) and \(M(q)\) can be constructed columnwise. The composite rigid body algorithm is a more advanced and faster algorithm for computing the inertial matrix. Overall, if the inverse dynamics algorithm is implemented and the computation time is not an issue, then the system level method is a good choice for calculating forward dynamics.</p> <p>Here is an example of how to compute the slow system-level method in Pinocchio:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">pinocchio</span> <span class="k">as</span> <span class="n">pin</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="n">urdf_path</span> <span class="o">=</span> <span class="sh">''</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">pin</span><span class="p">.</span><span class="nf">buildModelFromUrdf</span><span class="p">(</span><span class="n">urdf_path</span><span class="p">)</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="nf">createData</span><span class="p">()</span>

<span class="n">q</span> <span class="o">=</span> <span class="n">pin</span><span class="p">.</span><span class="nf">randomConfiguration</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
<span class="n">v</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">uniform</span><span class="p">(</span><span class="o">-</span><span class="n">np</span><span class="p">.</span><span class="n">pi</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="n">pi</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">nv</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
<span class="n">tau</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">uniform</span><span class="p">(</span><span class="o">-</span><span class="n">np</span><span class="p">.</span><span class="n">pi</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="n">pi</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">nv</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>

<span class="c1"># Calculate bias force
</span><span class="n">h</span> <span class="o">=</span> <span class="n">pin</span><span class="p">.</span><span class="nf">rnea</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">nv</span><span class="p">))</span>

<span class="c1"># Calculate inertia matrix
</span><span class="n">M</span> <span class="o">=</span> <span class="n">pin</span><span class="p">.</span><span class="nf">crba</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">q</span><span class="p">)</span>

<span class="c1"># Solve for joint accelerations
</span><span class="n">a</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">linalg</span><span class="p">.</span><span class="nf">solve</span><span class="p">(</span><span class="n">M</span><span class="p">,</span> <span class="n">tau</span> <span class="o">-</span> <span class="n">h</span><span class="p">)</span>
</code></pre></div></div> <h2 id="fast-propagation-method">Fast propagation method</h2> <p>The fast method for calculating the forward dynamics is based on the articulated body inertia and is known as the Articulated Body Algorithm (ABA). In contrast to the usual inertia that maps velocity to momentum, the articulated body inertia maps acceleration to force. Articulated body inertias only depend on the inertias of the individual bodies and the constraints imposed by the joints, making them functions of joint position variables and not velocity variables or various force terms.</p> <p>The ABA algorithm consists of three recursions: a forward pass, a backward pass, and a second forward pass. During the first forward pass, the algorithm computes velocities and bias terms. The backward pass calculates articulated-body inertias and bias forces. Finally, during the second forward pass, the algorithm computes the accelerations.</p> <p>Here is an example of how to compute the forward dynamics using ABA and Pinocchio:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">pinocchio</span> <span class="k">as</span> <span class="n">pin</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="n">urdf_path</span> <span class="o">=</span> <span class="sh">''</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">pin</span><span class="p">.</span><span class="nf">buildModelFromUrdf</span><span class="p">(</span><span class="n">urdf_path</span><span class="p">)</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="nf">createData</span><span class="p">()</span>

<span class="n">q</span> <span class="o">=</span> <span class="n">pin</span><span class="p">.</span><span class="nf">randomConfiguration</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">model</span><span class="p">)</span>
<span class="n">v</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">uniform</span><span class="p">(</span><span class="o">-</span><span class="n">np</span><span class="p">.</span><span class="n">pi</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="n">pi</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">nv</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
<span class="n">tau</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">uniform</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">nv</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>

<span class="n">a</span> <span class="o">=</span> <span class="n">pin</span><span class="p">.</span><span class="nf">aba</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">tau</span><span class="p">)</span>
</code></pre></div></div> <h1 id="hybrid-dynamics">Hybrid dynamics</h1> <p>Hybrid dynamics is a generalization of both forward and inverse dynamics. In hybrid dynamics, the forces are known at some joints, the accelerations at others, and the task is to calculate the unknown forces and accelerations. This approach is useful for introducing prescribed motions into a rigid-body system. The function that represents hybrid dynamics is:</p> \[\ddot q_{FD},\ \tau_{ID} = \mathrm{HD}(model, q, \dot q, \ddot q_{ID}, \tau_{FD})\] <p>Similar to forward dynamics, hybrid dynamics can be calculated using either the slow system-level method or the fast method, which involves a combination of the RNEA and ABA algorithms. Unfortunately, Pinocchio currently does not have a fast implementation for hybrid dynamics. However, the RNEA algorithm can still be used to compute the hybrid dynamics.</p> <p>To begin with, we can take the inverse dynamics equation:</p> \[M \ddot q = \tau - h\] <p>and split the joint acceleration vector \(\ddot q\) into two parts: \(\ddot q_{ID}\) and \(\ddot q_{FD}\), where \(\ddot q_{ID}\) represents the joint accelerations which we know, and \(\ddot q_{FD}\) represents the joint accelerations that we need to calculate. Similarly, let’s split the joint torque vector \(\tau\) into two parts: \(\tau_{ID}\) which we need to calculate and \(\tau_{FD}\) which we know. Using the split acceleration and torque vectors, we can rewrite the inverse dynamics as:</p> \[\begin{bmatrix} M_{11} &amp; M_{12} \\ M_{21} &amp; M_{22} \end{bmatrix} \begin{bmatrix} \ddot q_{ID} \\ \ddot q_{FD} \end{bmatrix} = \begin{bmatrix} \tau_{ID} \\ \tau_{FD} \end{bmatrix} - \begin{bmatrix} h_{ID} \\ h_{FD} \end{bmatrix}\] <p>Now, we can rearrange the equation so that all the unknowns are on the left-hand side, and all the knowns are on the right-hand side:</p> \[\begin{bmatrix} -1 &amp; M_{12} \\ 0 &amp; M_{22} \end{bmatrix} \begin{bmatrix} \tau_{ID} \\ \ddot q_{FD} \end{bmatrix} = \begin{bmatrix} 0 \\ \tau_{FD} \end{bmatrix} - \begin{bmatrix} M_{11}\ddot q_1 + h_{ID} \\ M_{21}\ddot q_1 + h_{FD} \end{bmatrix} = \begin{bmatrix} 0 \\ \tau_{FD} \end{bmatrix} - \begin{bmatrix} \tilde h_{ID} \\ \tilde h_{FD} \end{bmatrix}\] <p>From this final arrangement, it becomes clear that to solve hybrid dynamics, we need to perform the following steps:</p> <ol> <li>Calculate modified bias force using inverse dynamics equation: \(\tilde h = \mathrm{ID}(q, \dot q, [\ddot q_{ID}^T\ 0]^T)\)</li> <li>Calculate \(M_{22}\) (the easiest way is to compute full \(M\) and extract \(M_{22}\))</li> <li>Calculate unkonwn joint accelerations by solving \(M_{22} \ddot q_{FD} = \tau_{FD} - \tilde h_{FD}\)</li> <li>Calculate unknown joint torques \(\tau_{ID}\) via \(\tau = \tilde h + M [0 \ \ddot q_{FD}^T]^T\)</li> </ol> <p>Here is an example of how to compute the hybrid dynamics using Pinocchio:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">pinocchio</span> <span class="k">as</span> <span class="n">pin</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>

<span class="n">urdf_path</span> <span class="o">=</span> <span class="sh">''</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">pin</span><span class="p">.</span><span class="nf">buildModelFromUrdf</span><span class="p">(</span><span class="n">urdf_path</span><span class="p">)</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="nf">createData</span><span class="p">()</span>

<span class="n">n_id_joints</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">n_fd_joints</span> <span class="o">=</span> <span class="n">model</span><span class="p">.</span><span class="n">nv</span> <span class="o">-</span> <span class="n">n_id_joints</span>

<span class="n">q</span> <span class="o">=</span> <span class="n">pin</span><span class="p">.</span><span class="nf">randomConfiguration</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">model</span><span class="p">)</span>
<span class="n">v</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">uniform</span><span class="p">(</span><span class="o">-</span><span class="n">np</span><span class="p">.</span><span class="n">pi</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="n">pi</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">model</span><span class="p">.</span><span class="n">nv</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
<span class="n">a_id</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">uniform</span><span class="p">(</span><span class="o">-</span><span class="n">np</span><span class="p">.</span><span class="n">pi</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="n">pi</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">n_id_joints</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
<span class="n">tau_fd</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">uniform</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="p">(</span><span class="n">n_fd_joints</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>

<span class="n">a_tilde</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">vstack</span><span class="p">((</span><span class="n">a_id</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="nf">zeros</span><span class="p">((</span><span class="n">n_fd_joints</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
<span class="n">h_tilde</span> <span class="o">=</span> <span class="n">pin</span><span class="p">.</span><span class="nf">rnea</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">a_tilde</span><span class="p">)</span>
<span class="n">h_fd_tilde</span> <span class="o">=</span> <span class="n">h_tilde</span><span class="p">[</span><span class="n">n_fd_joints</span><span class="p">:,:]</span>

<span class="n">M</span> <span class="o">=</span> <span class="n">pin</span><span class="p">.</span><span class="nf">crba</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">data</span><span class="p">,</span> <span class="n">q</span><span class="p">)</span>
<span class="n">M22</span> <span class="o">=</span> <span class="n">M</span><span class="p">[</span><span class="n">n_id_joints</span><span class="p">:,</span><span class="n">n_id_joints</span><span class="p">:]</span>

<span class="n">a_fd</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">linalg</span><span class="p">.</span><span class="nf">solve</span><span class="p">(</span>
	<span class="n">M22</span><span class="p">,</span> 
	<span class="n">tau_fd</span> <span class="o">-</span> <span class="n">h_fd_tilde</span>
<span class="p">)</span>
<span class="n">tau_id</span> <span class="o">=</span> <span class="p">(</span><span class="n">h_tilde</span> <span class="o">+</span> <span class="n">M</span> <span class="o">@</span> <span class="n">np</span><span class="p">.</span><span class="nf">vstack</span><span class="p">((</span><span class="n">np</span><span class="p">.</span><span class="nf">zeros_like</span><span class="p">(</span><span class="n">a_id</span><span class="p">),</span> <span class="n">a_fd</span><span class="p">)))[:</span><span class="n">n_id_joints</span><span class="p">,:]</span>
</code></pre></div></div> <p>In conclusion, this post only provides an introduction to the complex and vast topic of robot dynamics. To gain a deeper understanding, it is highly recommended to read Roy Featherstone’s book “<a href="https://link.springer.com/book/10.1007/978-1-4899-7560-7">Rigid Body Dynamics Algorithms</a>” and Junggon Kim’s paper “<a href="https://www.cs.cmu.edu/~junggon/tools/liegroupdynamics.pdf">Lie Group Formulation of Articulated Rigid Body Dynamics</a>”.</p>]]></content><author><name></name></author><summary type="html"><![CDATA[A schematic representation of a two degree of freedom robot]]></summary></entry><entry><title type="html">Modeling deformable objects: the rigid finite element method</title><link href="https://shamilmamedov.github.io/blog/2023/rfem/" rel="alternate" type="text/html" title="Modeling deformable objects: the rigid finite element method"/><published>2023-03-01T09:00:00+00:00</published><updated>2023-03-01T09:00:00+00:00</updated><id>https://shamilmamedov.github.io/blog/2023/rfem</id><content type="html" xml:base="https://shamilmamedov.github.io/blog/2023/rfem/"><![CDATA[ <p style="align: left; text-align:center;"> <img src="/assets/img/blog/rfem_comparison.gif" alt="" width="65%"/> </p> <p>The robotics community has shown significant interest in deformable object manipulation in recent years, with workshops hosted at <a href="https://deformable-workshop.github.io/icra2022/">ICRA</a> and <a href="https://romado-workshop.github.io/ROMADO2022/">IROS</a> in 2022. Both model-based and model-free approaches rely on accurate simulators. The finite element method (FEM), a powerful tool from continuum mechanics, can be computationally expensive for control. <a href="https://books.google.de/books?id=PhD8FDAzNJEC&amp;printsec=frontcover&amp;source=gbs_book_other_versions_r&amp;redir_esc=y#v=onepage&amp;q&amp;f=false">The rigid finite element method</a> (RFEM) is a simpler and faster approach that can leverage existing rigid-body dynamics tools.</p> <p>While not a new method, the RFEM — also known as the extended-flexible joint method or pseudo-rigid body method — remains a valuable modeling technique in robotics. This post explores its basic principles, limitations, and trade-offs, and provides a practical tutorial on simulating simple deformable linear object in Python using the <a href="https://stack-of-tasks.github.io/pinocchio/">Pinocchio</a> library.</p> <p>Whether you’re a seasoned researcher or new to the field, this post offers valuable insights and practical guidance on using the RFEM to model deformable linear objects.</p> <h1 id="basics-of-the-rfem">Basics of the RFEM</h1> <p>RFEM is a pretty straightforward way to study deformable objects by dividing them into smaller parts called rigid finite elements (rfes) and connecting them with spring-damping elements (sde). The technique uses generalised coordinates based on the elements’ displacements to describe the position of the system.</p> <p>To make things clearer, let’s consider a simple example of a cylindrical rod attached to a motor, as you an see in Figure 1. This setup can be thought of as an elastic pendulum or a deformable linear object that is manipulated by a robot arm. For now, we will only talk about dominant bending flexibility and describe the displacements of each rfe relative to the preceding element.</p> <p style="align: left; text-align:center;"> <img src="/assets/img/blog/RFEM_orig.png" alt="" width="50%"/> <div class="caption">Figure 1. Deformable linear object toy setup</div> </p> <p>The RFEM discretizes in two stages:</p> <ol> <li>Primary division: dividing the deformable object of length \(L\) into relatively simple elements with finite dimension \(\Delta l\) and concentrating their spring and damping features at one point (see Figure 2a);</li> <li>Secondary division: isolating rfes between sdes from the primary division to obtain a system of rfes connected by sdes (see Figure 2b).</li> </ol> <p style="align: left; text-align:center;"> <img src="/assets/img/blog/RFEM_discr.png" alt="" width="55%"/> <div class="caption">Figure 2. Visualization of the RFEM discretization</div> </p> <p>After discretization, we can treat the system as a serial chain of rigid bodies and derive its dynamics using the Lagrange or the Newton-Euler methods. To illustrate the general form of the RFEM dynamics, let’s briefly go through the dynamics derivation using the Lagrange method. Let \(q = [q_a\ q_p]^T\) denote the vector of joint angles, with \(q_a\) being the active joint angle and \(q_p\) being the passive joint angles of sdes. Using generalized coordinates, we can write down the energy functions used in the Lagrangian method</p> \[K(q, \dot q) = \frac{1}{2}\dot q^T M(q) \dot q,\ P(q) = \frac{1}{2} q^T K q + \sum_{i=0}^{n_s + 1} m_i g_0 p_{C_i}, \ D(\dot q) = \frac{1}{2}\dot q^T D \dot q.\] <p>Here \(n_s\) is the number of segments, \(M(q)\) is the inertia matrix, \(K\) and \(D\) are the constant diagonal stiffness and damping matrices, respectively; \(m_i\) and \(p_{C_i}\) are \(i-\)the rfes mass and the center of mass, respectively; \(g_0 = [0\ 0\ -9.81]^T\) is the gravity acceleration vector. Applying the Lagrange equations</p> \[\frac{d}{dt}\left(\frac{\partial \mathcal{L}}{\partial \dot q} \right) - \frac{\partial \mathcal{L}}{\partial q} = - \frac{\partial D}{\partial \dot q}\] <p>with \(\mathcal{L} = K - P\) being the Lagrangian, we get the final expression for the RFEM dynamics:</p> \[M(q) \ddot{q} + C(q, \dot{q}) \dot{q} + K q + D \dot{q} + g(q) = B \tau \tag{*}\] <p>Comparing the final expression for RFEM dynamics to classical rigid-body manipulator dynamics, we see two new terms: \(Kq\) representing linear spring forces and \(D\dot q\) representing linear damper forces. Despite these new terms, the difference between RFEM dynamics and classical rigid-body dynamics is minor. Therefore, we can adapt existing efficient rigid-body algorithms to compute RFEM dynamics, and there is no need to implement new software.</p> <p>For simulation and control we often need state-space models. To convert the RFEM dynamics (*) to state-space form, we define a state vector \(x=[q\ \dot q]^T\) and input \(u:= \tau\):</p> \[\dot x = f(x, u) = \begin{bmatrix} \dot q \\ M(q)^{-1} (B\tau - C(q, \dot{q}) \dot{q} - K q - D \dot{q} - g(q)) \end{bmatrix} .\] <h1 id="parameters-of-rfes-and-sdes">Parameters of rfes and sdes</h1> <p>The mass \(m_i\), first moment of inertia \(h=m_i p_{C_i}\), and second moments of inertia \(I_i\) expressed in the frame located at the center of mass of an rfe are the fundamental parameters of the rfe. In the case of homogenous (constant density \(\rho\)) objects with constant cross-section, these inertial parameters can be calculated using standard formulas. For our toy example — for a homogenous cylicrical shape rfe with length \(l\) and diameter \(d\) (as in Figure 3) — formulae are:</p> \[m = \rho \frac {\pi d^2 l}{4},\ p_C = \left[\frac{l}{2}\ 0\ 0 \right]^T,\ I_{XX} = \frac{md^2}{8},\ I_{YY} = I_{ZZ} = \frac{m}{48}(3d^2 + 4l^2)\] <p>However, for deformable objects with varying cross-sections and more complex shapes, CAD software is required.</p> <p style="align: left; text-align:center;"> <img src="/assets/img/blog/RFEM_rfe.png" alt="" width="17%"/> <div class="caption">Figure 3. Cylindrical rfe</div> </p> <p>Linear spring and damping parameters are the basic parameters of the sde. The stiffness \(k_i\) of the spring is a three-dimensional diagonal matrix, while for the planar case, \(k_i\) is a scalar. Similarly, the damping parameters \(d_i\) also follow the same rule.</p> <p>The coefficients of stiffness and damping of the sde are based on the elasticity features of a beam segment with length \(\Delta l\), such that the real segment of the beam will deform in the same way and with the same velocities of deformation as the equivalent sde under the same load. For homogenous materials of a specific constant cross-section, there are readily available formulas to calculate these coefficients. For our toy example, formulae are</p> \[k_{XX} = G\frac{\pi d^4}{32 l},\ k_{YY} = k_{ZZ} = E\frac{\pi d^4}{64l}\] <p>where \(G\) is the shear modulus and \(E\) is Young’s modulus. However, for more complex shapes, CAD software must be utilized.</p> <h1 id="tutorial-implementing-the-rfem-with-pinocchio-to-simulate-flexible-pendulum">Tutorial: implementing the RFEM with Pinocchio to simulate flexible pendulum</h1> <p>The tutorial leverages Pinocchio, an amazing tool for robot dynamics! Developed by Justin Carpentier, Pinocchio implements Roy Featherstone algorithms in C++, making it incredibly efficient. But that’s not all - it’s also been extended with new algorithms for computing derivatives of dynamics algorithms, constrained dynamics, and more. The best part? You can generate dynamics algorithms as a Casadi function and use them in optimal controller design.</p> <p>In this tutorial (<a href="https://github.com/shamilmamedov/rfem">link to code</a>), we will define the setup using URDF, which supports geometry and inertial parameters but unfortunately doesn’t support joint elasticity. Therefore, we will use an additional <code class="language-plaintext highlighter-rouge">.yaml</code> file to define sde parameters. To modify the geometry and inertial parameters of the RFEM, you will need to manually update the URDF files. But it’s easy to modify sde parameters (which is the most fun part) from the <code class="language-plaintext highlighter-rouge">rod_params.py</code> file by changing the \(G\) and \(E\) values. You can even use this file to compute the inertial parameters for a desired cylindrical rod.</p> <h2 id="computing-dynamics">Computing dynamics</h2> <p>Now, to simulate the flexible pendulum, we need to compute the forward dynamics of the RFEM model. The most efficient algorithm to use for this is articulated rigid body (ABA). Unfortunately, ABA in Pinocchio doesn’t support flexible joints (sdes) by default. But fear not, we can restructure the RFEM dynamics equation to treat sde torques as an input to the system</p> \[M(q) \ddot{q} + C(q, \dot{q}) \dot{q} + g(q) = \tilde \tau\] <p>where \(\tilde \tau = B \tau - K q - D \dot{q}\). This is possible because sde joints are virtual and are not actuated.</p> <p>To implement the flexible pendulum model, I have created a <code class="language-plaintext highlighter-rouge">FlexiblePendulum</code> class in the <code class="language-plaintext highlighter-rouge">flexible_pendulum.py</code> module. This class takes the number of segments as input and builds the model in its <code class="language-plaintext highlighter-rouge">__init__</code> method. Additionally, the class contains several other useful methods:</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">elasticity_torques</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">q</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">dq</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="n">ndarray</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s"> Computes torques due to elastic elements in the
    joints: spring-damper elements
    NOTE the first joint -- active joint -- doesn</span><span class="sh">'</span><span class="s">t
         have spring-damper element in it

    :param q: joint positions
    :param dq: joint velocities

    :return: torques 
    </span><span class="sh">"""</span>
    <span class="k">return</span> <span class="o">-</span><span class="n">self</span><span class="p">.</span><span class="n">K</span> <span class="o">@</span> <span class="n">q</span> <span class="o">-</span> <span class="n">self</span><span class="p">.</span><span class="n">D</span> <span class="o">@</span> <span class="n">dq</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">forward_dynamics</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">q</span><span class="p">:</span><span class="n">np</span><span class="p">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">dq</span><span class="p">:</span><span class="n">np</span><span class="p">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">tau_a</span><span class="p">:</span><span class="n">np</span><span class="p">.</span><span class="n">ndarray</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s"> Computes forward dynamics

    :param q: joint positions
    :param dq: joint velocities
    :param tau_a: active joints torque

    :return: ddq -- aceelerations of all joints, active and passive 
    </span><span class="sh">"""</span>
    <span class="n">tau</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">B</span> <span class="o">@</span> <span class="n">tau_a</span> <span class="o">+</span> <span class="n">self</span><span class="p">.</span><span class="nf">elasticity_torques</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">dq</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">pin</span><span class="p">.</span><span class="nf">aba</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">model</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">data</span><span class="p">,</span> <span class="n">q</span><span class="p">,</span> <span class="n">dq</span><span class="p">,</span> <span class="n">tau</span><span class="p">).</span><span class="nf">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
</code></pre></div></div> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">ode</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="n">ndarray</span><span class="p">,</span> <span class="n">u</span><span class="p">:</span> <span class="n">np</span><span class="p">.</span><span class="n">ndarray</span><span class="p">):</span>
    <span class="sh">"""</span><span class="s"> Computes ode of the robot

    :param x: robot state
    :param u: active joint torque

    :return: x_dot
    </span><span class="sh">"""</span>
    <span class="n">q</span><span class="p">,</span> <span class="n">dq</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">split</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="nf">vstack</span><span class="p">((</span><span class="n">dq</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="nf">forward_dynamics</span><span class="p">(</span><span class="n">q</span><span class="p">,</span> <span class="n">dq</span><span class="p">,</span> <span class="n">u</span><span class="p">)))</span>
</code></pre></div></div> <h2 id="integrating-rfem-dynamics">Integrating RFEM dynamics</h2> <p>It’s important to note that RFE dynamics can be quite <a href="https://en.wikipedia.org/wiki/Stiff_equation">stiff</a>, and using fixed-step integrators can result in divergence if the step size is too large. To avoid this problem, I have opted to use a variable step Runge-Kutta integrator from the <code class="language-plaintext highlighter-rouge">scipy.integrate</code> package in this tutorial.</p> <p>In order to simulate the flexible pendulum system, I have implemented a <code class="language-plaintext highlighter-rouge">simulate_flexible_pendulum</code> function in the <code class="language-plaintext highlighter-rouge">simulation.py</code> module. Additionally, to incorporate a controller into the simulation, I created a <code class="language-plaintext highlighter-rouge">controllers.py</code> file which contains an abstract <code class="language-plaintext highlighter-rouge">BaseController</code> class. To provide concrete implementations of controllers, I created a <code class="language-plaintext highlighter-rouge">DummyController</code> class that always returns zero torque, and a <code class="language-plaintext highlighter-rouge">PDController</code> that implements a proportional-derivative controller. By inheriting from the <code class="language-plaintext highlighter-rouge">BaseController</code> class, it is easy to create new controllers as needed.</p> <p>By using the variable step integrator and implementing controllers, we can now simulate the flexible pendulum system and explore its behavior under various conditions.</p> <h2 id="visualization">Visualization</h2> <p>Pinocchio provides several options for visualizing robots. In order to visualize the motion of the flexible pendulum system, I have implemented visualize_elastic_pendulum function in the <code class="language-plaintext highlighter-rouge">visualization.py</code> module which can use either the Meshcat or Panda3d visualizers of Pinocchio.</p> <h2 id="some-simulation-results">Some simulation results</h2> <p>When using RFEM to model deformable objects, the accuracy is greatly influenced by the level of discretization. Specifically, the approximation of natural frequency of the continuum material is impacted. As with any discretization method, increasing the level of discretization improves the accuracy of the approximation.</p> <p>To demonstrate this visually, let’s analyze the motion of a pendulum using three different discretizations: models with 3, 5, and 10 segments. If you’re interested in a more quantitative analysis, please refer to <a href="https://arxiv.org/abs/2212.02941">preprint of our paper</a> or <a href="https://books.google.de/books?id=PhD8FDAzNJEC&amp;printsec=frontcover&amp;source=gbs_book_other_versions_r&amp;redir_esc=y#v=onepage&amp;q&amp;f=false">the RFEM book</a>.</p> <p>We’ll use a PD controller with a zero reference for the active angle \(q_a^r = 0\) rad for 2.5 seconds, then change the reference to \(q_a^r = \pi/4\) rad for the next 2.5 seconds. The GIF below visualizes the motion of all three models. While there may be small synchronization errors, there is a noticeable difference: the model with 3 segments behaves differently compared to the models with 5 and 10 segments, which move similarly.</p> <p style="align: left; text-align:center;"> <img src="/assets/img/blog/rfem_comparison.gif" alt="" width="65%"/> </p> <h2 id="final-comments-and-recommendations">Final comments and recommendations</h2> <p>If you clone the code and run <code class="language-plaintext highlighter-rouge">main.py</code> with a 10-segment discretization, you’ll notice that the integration is quite slow. This is due to two reasons: (i) the <code class="language-plaintext highlighter-rouge">scipy</code> implementation of RK45 is inefficient and (ii) the state-space dimension is simply too large. In the past, I used the <a href="https://computing.llnl.gov/projects/sundials/cvodes">CVODES</a> integrator, which resulted in a much faster simulation time. Alternatively, fixed-step implicit integrators are a good choice for optimization-based control.</p> <p>Overall, the RFEM method is a straightforward way to model deformable objects, and it can make use of existing tools for modeling rigid robots. However, one of its main limitations is that it requires very fine discretization to accurately model deformable objects, which can result in slow computation times.</p>]]></content><author><name></name></author><summary type="html"><![CDATA[]]></summary></entry></feed>